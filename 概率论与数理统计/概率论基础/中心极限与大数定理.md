# 大数定律及中心极限定理

# 切比雪夫不等式

假设随机变量 $X$ 具有期望 $\mathbb{E}[X]=\mu$，方差 $\operatorname{Var}(X)=\sigma^{2}$，则对于任意正数 $\varepsilon$，下列不等式成立：

$$
P\{|X-\mu| \geq \varepsilon\} \leq \frac{\sigma^{2}}{\varepsilon^{2}}
$$

其意义在于，对于距离 $\mathbb{E}[X]$ 足够远的地方（距离大于等于 $\varepsilon$），事件出现的概率是小于等于 $\frac{\sigma^{2}}{\varepsilon^{2}}$，即事件出现在区间 $[\mu-\varepsilon, \mu+\varepsilon]$ 的概率大于等于 $1-\frac{\sigma^{2}}{\varepsilon^{2}}$。该不等式给出了随机变量 $X$ 在分布未知的情况下，事件 $\{|X-\mu| \leq \varepsilon\}$ 的下限估计，如：

$$
P\{|X-\mu|<3 \sigma\} \geq 0.8889
$$

该不等式的证明为：

$$
\begin{aligned} P\{|X-\mu| \geq \varepsilon& \}=\int_{|x-\mu| \geq \varepsilon} p(x) d x \leq \int_{|x-\mu| \geq \varepsilon} \frac{|x-\mu|^{2}}{\varepsilon^{2}} p(x) d x \\ & \leq \frac{1}{\varepsilon^{2}} \int_{-\infty}^{\infty}(x-\mu)^{2} p(x) d x=\frac{\sigma^{2}}{\varepsilon^{2}} \end{aligned}
$$

切比雪夫不等式的特殊情况：假设随机变量 $X_{1}, X_{2}, \cdots, X_{n}, \cdots$ 相互独立，且具有相同的数学期望和方差：$\mathbb{E}\left[X_{k}\right]=\mu, \operatorname{Var}\left[X_{k}\right]=\sigma^{2}$。作前 $n$ 个随机变量的算术平均：$\overline{X}=\frac{1}{n} \sum_{k=1}^{n} X_{k}$，则对于任意正数 $\varepsilon$ 有：

$$
\lim _{n \rightarrow \infty} P\{|\overline{X}-\mu|<\varepsilon\}=\lim _{n \rightarrow \infty} P\left\{\left|\frac{1}{n} \sum_{k=1}^{n} X_{k}-\mu\right|<\varepsilon\right\}=1
$$

证明过程为，根据期望和方差的性质有：$\mathbb{E}[\overline{X}]=\mu, \quad \operatorname{Var}[\overline{X}]=\frac{\sigma^{2}}{n}$，根据切比雪夫不等式有：

$$
P\{|\overline{X}-\mu| \geq \varepsilon\} \leq \frac{\sigma^{2}}{n \varepsilon^{2}}
$$

则有 $\lim _{n \rightarrow \infty} P\{|\overline{X}-\mu| \geq \varepsilon\}=0$，因此有 $\lim _{n \rightarrow \infty} P\{|\overline{X}-\mu|<\varepsilon\}=1$。

# 大数定理

假设 $Y_{1}, Y_{2}, \cdots, Y_{n}, \cdots$ 是一个随机变量序列，$a$ 是一个常数，如果对于任意正数 $\varepsilon$ 存在：

$$
\lim _{n \rightarrow \infty} P\left\{\left|Y_{n}-a\right| \leq \varepsilon\right\}=1
$$

则称序列 $Y_{1}, Y_{2}, \cdots, Y_{n}, \cdots$ 依概率收敛于 $a$，记作：$Y_{n} \stackrel{P}{\rightarrow} a$。

依概率收敛包含两层意思，收敛表明这是一个随机变量序列，而不是某个随机变量；且序列是无限长，而不是有限长。依概率则表明序列无穷远处的随机变量 $Y_{\infty}$ 的分布规律为：绝大部分分布于点 $a$，极少数位于 $a$ 之外。且分布于 $a$ 之外的事件发生的概率之和为 0。

## 大数定理一

假设随机变量 $X_{1}, X_{2}, \cdots, X_{n}, \cdots$ 相互独立，且具有相同的数学期望和方差：$\mathbb{E}\left[X_{k}\right]=\mu, \operatorname{Var}\left[X_{k}\right]=\sigma^{2}$。则序列：

$$
\overline{X}=\frac{1}{n} \sum_{k=1}^{n} X_{k}
$$

依概率收敛于 $\mu$，即 $\overline{X} \stackrel{P}{\rightarrow} \mu$。值得一提的是，这里并没有要求随机变量 $X_{1}, X_{2}, \cdots, X_{n}, \cdots$ 同分布。

## 伯努利大数定理

假设 $n_{A}$ 为 $n$ 次独立重复实验中事件 $A$ 发生的次数，$p$ 是事件 $A$ 在每次试验中发生的概率。则对于任意正数 $\varepsilon$ 有：

$$
\begin{array}{c}{\lim _{n \rightarrow \infty} P\left\{\left|\frac{n_{A}}{n}-p\right|<\varepsilon\right\}=1} \\ {\text { or: } \quad \lim _{n \rightarrow \infty} P\left\{\left|\frac{n_{A}}{n}-p\right| \geq \varepsilon\right\}=0}\end{array}
$$

即当独立重复实验执行非常大的次数时，事件 $A$ 发生的频率逼近于它的概率。

## 辛钦定理

假设随机变量 $X_{1}, X_{2}, \cdots, X_{n}, \cdots$ 相互独立，服从同一分布，且具有相同的数学期望：$\mathbb{E}\left[X_{k}\right]=\mu$，则对于任意正数 $\varepsilon$ 存在：

$$
\lim _{n \rightarrow \infty} P\left\{\left|\frac{1}{n} \sum_{k=1}^{n} X_{k}-\mu\right|<\varepsilon\right\}=1
$$

注意：这里并没有要求随机变量 $X_{1}, X_{2}, \cdots, X_{n}, \cdots$ 的方差存在，伯努利大数定理是亲钦定理的特殊情况。

# 中心极限定理

## 独立同分布的中心极限定理

假设随机变量 $X_{1}, X_{2}, \cdots, X_{n}, \cdots$ 独立同分布，且具有数学期望和方差：$\mathbb{E}\left[X_{k}\right]=\mu, \operatorname{Var}\left[X_{k}\right]=\sigma^{2}$，则随机变量之和 $\overline{S X_{n}}=\sum_{k=1}^{n} X_{k}$ 的标准变化量：

$$
Y_{n}=\frac{\overline{S X_{n}}-\mathbb{E}\left[\overline{S X_{n}}\right]}{\sqrt{\operatorname{Var}\left[\overline{S X_{n}}\right]}}=\frac{\overline{S X_{n}}-n \mu}{\sqrt{n} \sigma}
$$

的概率分布函数 $F_{n}(x)$ 对于任意 $x$ 满足：

$$
\begin{array}{c}{\lim _{n \rightarrow \infty} F_{n}(x)=\lim _{n \rightarrow \infty} P\left\{Y_{n} \leq x\right\}=\lim _{n \rightarrow \infty} P\left\{\frac{\sum_{k=1}^{n} X_{k}-n \mu}{\sqrt{n} \sigma} \leq x\right\}} \\ {=\int_{-\infty}^{x} \frac{1}{\sqrt{2 \pi}} e^{-t^{2} / 2} d t=\Phi(x)}\end{array}
$$

其物理意义在于，均值方差为 $\mu, \sigma^{2}$ 的独立同分布的随机变量 $X_{1}, X_{2}, \cdots, X_{n}, \cdots$ 之和 $\overline{S X_{n}}=\sum_{k=1}^{n} X_{k}$ 的标准变化量 $Y_n$，当 $n$ 充分大时，其分布近似于标准正态分布。

即 $\overline{S X_{n}}=\sum_{k=1}^{n} X_{k}$ 在 $n$ 充分大时，其分布近似于 $N\left(n \mu, n \sigma^{2}\right)$。一般情况下，很难求出 $n$ 个随机变量之和的分布函数。因此当 $n$ 充分大时，可以通过正态分布来做理论上的分析或者计算。

## Liapunov 定理

假设随机变量 $X_{1}, X_{2}, \cdots, X_{n}, \cdots$ 相互独立，具有数学期望和方差：$\mathbb{E}\left[X_{k}\right]=\mu_{k}, \operatorname{Var}\left[X_{k}\right]=\sigma_{k}^{2}$。

记 $B_{n}^{2}=\sum_{k=1}^{n} \sigma_{k}^{2}$，如果存在正数 $\delta$，使得 $n \rightarrow \infty$ 时：

$$
\frac{1}{B_{n}^{2+\delta}} \sum_{k=1}^{n} \mathbb{E}\left[\left|X_{k}-\mu_{k}\right|^{2+\delta}\right] \rightarrow 0
$$

则随机变量之和 $\overline{S X_{n}}=\sum_{k=1}^{n} X_{k}$ 的标准变化量：

$$
Z_{n}=\frac{\overline{S X_{n}}-\mathbb{E}\left[\overline{S X_{n}}\right]}{\sqrt{\operatorname{Var}\left[\overline{S X_{n}}\right]}}=\frac{\overline{S X_{n}}-\sum_{k=1}^{n} \mu_{k}}{B_{n}}
$$

的概率分布函数 $F_{n}(x)$ 对于任意 $x$ 满足：

$$
\begin{aligned} \lim _{n \rightarrow \infty} F_{n}(x)=\lim _{n \rightarrow \infty} & P\left\{Z_{n} \leq x\right\}=\lim _{n \rightarrow \infty} P\left\{\frac{\sum_{k=1}^{n} X_{k}-\sum_{k=1}^{n} \mu_{k}}{B_{n}} \leq x\right\} \\ &=\int_{-\infty}^{x} \frac{1}{\sqrt{2 \pi}} e^{-t^{2} / 2} d t=\Phi(x) \end{aligned}
$$

其物理意义在于，相互独立的随机变量 $X_{1}, X_{2}, \cdots, X_{n}, \cdots$ 之和 $\overline{S X_{n}}=\sum_{k=1}^{n} X_{k}$ 的衍生随机变量序列 $Z_{n}=\frac{\overline{S X_{n}}-\sum_{k=1}^{n} \mu_{k}}{B_{n}}$，当 $n$ 充分大时，其分布近似于标准正态分布。注意，这里同样不要求 $X_{1}, X_{2}, \cdots, X_{n}, \cdots$ 同分布。

## Demoiver-Laplace 定理

假设随机变量序列 $\eta_{n}, n=1,2, \dots$ 服从参数为 $(n, p)$ 的二项分布，其中 $0<p<1$。则对于任意 $x$ 有：

$$
\lim _{n \rightarrow \infty} P\left\{\frac{\eta_{n}-n p}{\sqrt{n p(1-p)}} \leq x\right\}=\int_{-\infty}^{x} \frac{1}{\sqrt{2 \pi}} e^{-t^{2} | 2} d t=\Phi(x)
$$

该定理表明，正态分布是二项分布的极限分布。当 $n$ 充分大时，可以利用正态分布来计算二项分布的概率。
