# AI Math Notes | AI 中的数学基础

## 1. 统计学习理论

### 1.1 学习理论基础

- VC 维理论

  - VC 维的定义
  - 增长函数
  - 打散系数
  - 样本复杂度

- PAC 学习框架

  - PAC 可学习性
  - 样本复杂度界
  - 假设空间
  - 一致收敛

- 复杂度度量

  - Rademacher 复杂度
  - 覆盖数与容量
  - 经验风险最小化
  - 结构风险最小化

- 泛化理论
  - 泛化误差界
  - 一致性分析
  - 稳定性理论
  - 收敛率分析

### 1.2 正则化理论

- L1 正则化

  - Lasso 理论
  - 稀疏性分析
  - 特征选择
  - 路径算法

- L2 正则化

  - Ridge 回归
  - 权重衰减
  - 条件数改善
  - 解的稳定性

- 组合正则化

  - Elastic Net
  - 组稀疏
  - 核范数
  - 图正则化

- 模型选择
  - 交叉验证
  - 早停法
  - 信息准则
  - 模型平均

## 2. 矩阵分析与降维

### 2.1 矩阵分解理论

- 特征值分解

  - 特征向量与特征值
  - 谱分解
  - 对称矩阵性质
  - 正定矩阵

- 奇异值分解

  - SVD 理论
  - 截断 SVD
  - 低秩近似
  - 矩阵补全

- 高级分解方法
  - 非负矩阵分解(NMF)
  - 稀疏编码
  - 字典学习
  - 张量分解

### 2.2 降维理论

- 线性降维

  - 主成分分析(PCA)
  - 线性判别分析(LDA)
  - 因子分析
  - 多维尺度分析(MDS)

- 非线性降维

  - 核 PCA
  - 流形学习
  - t-SNE
  - UMAP

- 特征选择
  - 过滤法
  - 包装法
  - 嵌入法
  - 自动特征工程

## 3. 概率图模型与深度学习

### 3.1 概率图模型

- 贝叶斯网络

  - 条件独立性
  - 因果推断
  - 结构学习
  - 参数学习

- 马尔可夫模型

  - 马尔可夫随机场
  - 条件随机场
  - 吉布斯采样
  - 能量函数

- 变分推断
  - 变分下界
  - EM 算法
  - 变分贝叶斯
  - 随机变分推断

### 3.2 深度学习数学基础

- 反向传播

  - 计算图
  - 链式法则
  - 自动微分
  - 梯度流

- 激活函数

  - ReLU 及其变体
  - Sigmoid 族
  - 数学性质
  - 梯度特性

- 损失函数

  - 交叉熵
  - KL 散度
  - 对比损失
  - 正则化项

- 优化理论
  - 随机梯度下降
  - 动量方法
  - 自适应算法
  - 二阶优化

## 4. 信息论与最优化

### 4.1 信息论基础

- 基本概念

  - 熵
  - 互信息
  - 条件熵
  - 相对熵

- 编码理论
  - 最优编码
  - 数据压缩
  - 信道容量
  - 率失真理论

### 4.2 最优化方法

- 凸优化

  - 凸集与凸函数
  - KKT 条件
  - 对偶理论
  - 内点法

- 非凸优化
  - 局部最优
  - 鞍点逃逸
  - 全局优化
  - 随机优化
